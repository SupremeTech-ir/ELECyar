import asyncio
import os
import random
import re
from playwright.async_api import async_playwright
from urllib.parse import urljoin, urlparse

# Configuration - Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªØºÛŒÛŒØ±
BASE_URL = "https://eshop.eca.ir"
OUTPUT_DIR = "scraped_data"
MIN_DELAY = 3  # Ø­Ø¯Ø§Ù‚Ù„ ÙˆÙ‚ÙÙ‡ Ø¨ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ (Ø«Ø§Ù†ÛŒÙ‡)
MAX_DELAY = 8  # Ø­Ø¯Ø§Ú©Ø«Ø± ÙˆÙ‚ÙÙ‡ Ø¨ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ (Ø«Ø§Ù†ÛŒÙ‡)
MAX_PAGES = None  # ØªØ¹Ø¯Ø§Ø¯ ØµÙØ­Ø§Øª Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± (None = Ù‡Ù…Ù‡ ØµÙØ­Ø§Øª)
SCRAPED_URLS_FILE = "scraped_urls.txt"  # ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ URLÙ‡Ø§ÛŒ Ø§Ø³Ú©Ø±Ù¾ Ø´Ø¯Ù‡

# Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø±ØªØ¨Ø·
CATEGORIES = {
    "Ù…Ù‚Ø§ÙˆÙ…Øª": ["Ù…Ù‚Ø§ÙˆÙ…Øª", "resistor"],
    "Ø®Ø§Ø²Ù†": ["Ø®Ø§Ø²Ù†", "capacitor"],
    "Ø³Ù„Ù": ["Ø³Ù„Ù", "inductor", "coil"],
    "Ø¯ÛŒÙˆØ¯": ["Ø¯ÛŒÙˆØ¯", "diode"],
    "Ø¢ÛŒ Ø³ÛŒ - ØªØ±Ø§Ø´Ù‡": ["Ø¢ÛŒ Ø³ÛŒ", "ØªØ±Ø§Ø´Ù‡", "ic", "chip"],
    "Ù…ÛŒÚ©Ø±ÙˆÚ©Ù†ØªØ±Ù„Ø± Ùˆ Ù¾Ø±ÙˆØ³Ø³ÙˆØ±": ["Ù…ÛŒÚ©Ø±ÙˆÚ©Ù†ØªØ±Ù„Ø±", "Ù…ÛŒÚ©Ø±Ùˆ Ú©Ù†ØªØ±Ù„Ø±", "Ù¾Ø±ÙˆØ³Ø³ÙˆØ±", "microcontroller", "processor", "mcu"],
    "Ø±Ú¯ÙˆÙ„Ø§ØªÙˆØ±": ["Ø±Ú¯ÙˆÙ„Ø§ØªÙˆØ±", "regulator"],
    "ØªØ±Ø§Ù†Ø²ÛŒØ³ØªÙˆØ±": ["ØªØ±Ø§Ù†Ø²ÛŒØ³ØªÙˆØ±", "transistor"],
    "ØªØ±Ø§ÛŒØ§Ú© Ùˆ ØªØ±ÛŒØ³ØªÙˆØ±": ["ØªØ±Ø§ÛŒØ§Ú©", "ØªØ±ÛŒØ³ØªÙˆØ±", "triac", "thyristor"],
    "LED Ùˆ ØªØ¬Ù‡ÛŒØ²Ø§Øª Ù…Ø±ØªØ¨Ø·": ["led", "Ø§Ù„ Ø§ÛŒ Ø¯ÛŒ"],
    "Ø³Ú¯Ù…Ù†Øª Ùˆ Ù…Ø§ØªØ±ÛŒØ³": ["Ø³Ú¯Ù…Ù†Øª", "Ù…Ø§ØªØ±ÛŒØ³", "segment", "matrix"],
    "Ú©Ø±ÛŒØ³ØªØ§Ù„ Ùˆ Ø§Ø³ÛŒÙ„Ø§ØªÙˆØ±": ["Ú©Ø±ÛŒØ³ØªØ§Ù„", "Ø§Ø³ÛŒÙ„Ø§ØªÙˆØ±", "crystal", "oscillator"],
    "ÙˆØ±ÛŒØ³ØªÙˆØ±": ["ÙˆØ±ÛŒØ³ØªÙˆØ±", "varistor"],
    "Ø±Ù„Ù‡": ["Ø±Ù„Ù‡", "relay"],
    "Ù¾ÛŒÙ† Ù‡Ø¯Ø±": ["Ù¾ÛŒÙ† Ù‡Ø¯Ø±", "pin header", "header"],
    "Ø³ÙˆÙƒØªØŒ Ú©Ø§Ù†Ú©ØªÙˆØ±ØŒ ÙÛŒØ´": ["Ø³ÙˆÚ©Øª", "Ú©Ø§Ù†Ú©ØªÙˆØ±", "ÙÛŒØ´", "socket", "connector"],
    "Ú©Ù„ÛŒØ¯ØŒ Ø³ÙˆØ¦ÛŒÚ†ØŒ Ú©ÛŒÙ¾Ø¯": ["Ú©Ù„ÛŒØ¯", "Ø³ÙˆØ¦ÛŒÚ†", "Ú©ÛŒÙ¾Ø¯", "switch", "keypad", "button"],
    "ØªØ±Ù…ÛŒÙ†Ø§Ù„ Ù¾ÛŒÚ†ÛŒ Ùˆ Ú©Ø´ÙˆÛŒÛŒ": ["ØªØ±Ù…ÛŒÙ†Ø§Ù„", "terminal"],
    "ÙÛŒÙˆØ²": ["ÙÛŒÙˆØ²", "fuse"],
    "Ø¨Ø§Ø²Ø±ØŒ Ù¾ÛŒØ²Ùˆ Ùˆ Ø¨Ù„Ù†Ø¯Ú¯Ùˆ": ["Ø¨Ø§Ø²Ø±", "Ù¾ÛŒØ²Ùˆ", "Ø¨Ù„Ù†Ø¯Ú¯Ùˆ", "buzzer", "piezo", "speaker"],
    "Ø¢Ù†ØªÙ†": ["Ø¢Ù†ØªÙ†", "antenna"],
    "Ø±ÛŒÙ…ÙˆØª Ú©Ù†ØªØ±Ù„Ø±": ["Ø±ÛŒÙ…ÙˆØª", "remote"],
    "ÙÛŒØ¨Ø± Ù…Ø¯Ø§Ø± Ú†Ø§Ù¾ÛŒ - Ø¨Ø±Ø¯ Ø¨ÙˆØ±Ø¯": ["ÙÛŒØ¨Ø±", "Ø¨Ø±Ø¯", "pcb", "breadboard", "Ø¨ÙˆØ±Ø¯"],
    "Ø³ÛŒÙ… Ùˆ Ú©Ø§Ø¨Ù„": ["Ø³ÛŒÙ…", "Ú©Ø§Ø¨Ù„", "wire", "cable"],
    "ØªØ±Ø§Ù†Ø³ØŒ Ú†ÙˆÚ©ØŒ ÙØ±ÛŒØªØŒ Ù‡Ø³ØªÙ‡": ["ØªØ±Ø§Ù†Ø³", "Ú†ÙˆÚ©", "ÙØ±ÛŒØª", "Ù‡Ø³ØªÙ‡", "transformer", "choke", "ferrite", "core"],
    "Ù¾ÙˆÚ¯Ùˆ Ù¾ÛŒÙ† - Ù¾ÛŒÙ† ØªØ³Øª": ["Ù¾ÙˆÚ¯Ùˆ", "Ù¾ÛŒÙ† ØªØ³Øª", "pogo", "test pin"],
    "ÙÙ† Ùˆ Ù…Ø­Ø§ÙØ¸ ÙÙ†": ["ÙÙ†", "fan"],
    "Ù‡ÛŒØª Ø³ÛŒÙ†Ú© Ùˆ Ø§Ù„Ù…Ø§Ù† Ø­Ø±Ø§Ø±ØªÛŒ": ["Ù‡ÛŒØª Ø³ÛŒÙ†Ú©", "Ø§Ù„Ù…Ø§Ù† Ø­Ø±Ø§Ø±ØªÛŒ", "heat sink", "heatsink"],
    "Ù„ÛŒØ²Ø±": ["Ù„ÛŒØ²Ø±", "laser"],
    "Ø§Ø³Ù¾Ø§Ø±Ú© Ú¯Ù¾": ["Ø§Ø³Ù¾Ø§Ø±Ú© Ú¯Ù¾", "spark gap"],
    "Ù¾ÛŒÚ† Ùˆ Ø§Ø³Ù¾ÛŒØ³Ø±": ["Ù¾ÛŒÚ†", "Ø§Ø³Ù¾ÛŒØ³Ø±", "screw", "spacer"],
    "Ø¬Ø¹Ø¨Ù‡ Ùˆ Ú©ÛŒØ³ Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø§Ù„Ú©ØªØ±ÙˆÙ†ÛŒÚ©ÛŒ": ["Ø¬Ø¹Ø¨Ù‡", "Ú©ÛŒØ³", "box", "case", "enclosure"],
    "Ø¨Ø±Ù‚ Ø³Ø§Ø®ØªÙ…Ø§Ù†": ["Ø¨Ø±Ù‚ Ø³Ø§Ø®ØªÙ…Ø§Ù†", "Ù¾Ø±ÛŒØ²", "Ú©Ù„ÛŒØ¯ Ø¨Ø±Ù‚"],
    "ØªØ¬Ù‡ÛŒØ²Ø§Øª ØªØ¹Ù…ÛŒØ± Ù…ÙˆØ¨Ø§ÛŒÙ„": ["ØªØ¬Ù‡ÛŒØ²Ø§Øª ØªØ¹Ù…ÛŒØ± Ù…ÙˆØ¨Ø§ÛŒÙ„", "mobile repair tools", "Ù…ÙˆØ¨Ø§ÛŒÙ„"],
    "ØªØ¬Ù‡ÛŒØ²Ø§Øª ØªØ³Øª Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú¯ÛŒØ±ÛŒ": ["ØªØ¬Ù‡ÛŒØ²Ø§Øª ØªØ³Øª", "ØªØ¬Ù‡ÛŒØ²Ø§Øª Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú¯ÛŒØ±ÛŒ", "test equipment", "measurement equipment"],
    "Ù…ÙˆÙ„ØªÛŒ Ù…ØªØ±": ["Ù…ÙˆÙ„ØªÛŒ Ù…ØªØ±", "multimeter", "Ú†Ù†Ø¯ Ù…ØªØ±"],
    "Ø§Ø³ÛŒÙ„ÙˆØ³Ú©ÙˆÙ¾ Ùˆ Ù„Ø§Ø¬ÛŒÚ© Ø¢Ù†Ø§Ù„Ø§ÛŒØ²Ø±": ["Ø§Ø³ÛŒÙ„ÙˆØ³Ú©ÙˆÙ¾", "Ù„Ø§Ø¬ÛŒÚ© Ø¢Ù†Ø§Ù„Ø§ÛŒØ²Ø±", "oscilloscope", "logic analyzer"],
    "Ù¾Ø±Ø§Ø¨ Ùˆ Ú©Ø§Ø¨Ù„ ØªØ³Øª": ["Ù¾Ø±Ø§Ø¨", "Ú©Ø§Ø¨Ù„ ØªØ³Øª", "probe", "test cable"],
    "Ø¢Ù„ØªØ±Ø§Ø³ÙˆÙ†ÛŒÚ© Ú©Ù„ÛŒÙ†Ø±": ["Ø¢Ù„ØªØ±Ø§Ø³ÙˆÙ†ÛŒÚ© Ú©Ù„ÛŒÙ†Ø±", "ultrasonic cleaner", "Ø¯Ø³ØªÚ¯Ø§Ù‡ ØªÙ…ÛŒØ² Ú©Ù†Ù†Ø¯Ù‡"],
    "Ù…ÛŒÚ©Ø±ÙˆØ³Ú©ÙˆÙ¾ Ùˆ Ø°Ø±Ù‡ Ø¨ÛŒÙ†": ["Ù…ÛŒÚ©Ø±ÙˆØ³Ú©ÙˆÙ¾", "Ø°Ø±Ù‡ Ø¨ÛŒÙ†", "microscope", "magnifying glass"],
    "Ø¯Ù…Ø§Ø³Ù†Ø¬ Ùˆ Ø±Ø·ÙˆØ¨Øª Ø³Ù†Ø¬": ["Ø¯Ù…Ø§Ø³Ù†Ø¬", "Ø±Ø·ÙˆØ¨Øª Ø³Ù†Ø¬", "thermometer", "hygrometer", "temperature", "humidity meter"],
    "Ø§Ù†ÙˆØ§Ø¹ Ù¾ÛŒÚ† Ú¯ÙˆØ´ØªÛŒ Ùˆ Ø¢Ú†Ø§Ø±": ["Ù¾ÛŒÚ† Ú¯ÙˆØ´ØªÛŒ", "Ø¢Ú†Ø§Ø±", "screwdriver", "wrench"],
    "Ø¢Ù„Ù† Ø¢Ú†Ø§Ø±": ["Ø¢Ù„Ù† Ø¢Ú†Ø§Ø±", "allen key", "hex key"],
    "Ø¢Ú†Ø§Ø± Ø³ÙˆÚ©Øª Ø²Ù† Ùˆ Ù¾Ø±Ø³ÛŒ": ["Ø¢Ú†Ø§Ø± Ø³ÙˆÚ©Øª Ø²Ù†", "Ù¾Ø±Ø³ÛŒ", "socket wrench", "press tool"],
    "Ø§Ø¨Ø²Ø§Ø± Ø³ÙˆØ±Ø§Ø® Ú©Ø§Ø±ÛŒ Ùˆ Ø¨Ø±Ø´": ["Ø§Ø¨Ø²Ø§Ø± Ø³ÙˆØ±Ø§Ø® Ú©Ø§Ø±ÛŒ", "Ø§Ø¨Ø²Ø§Ø± Ø¨Ø±Ø´", "drilling tool", "cutting tool"],
    "Ø§Ø³Ù¾Ø±ÛŒ Ø³Ø´ÙˆØ§Ø± Ùˆ Ú†Ø³Ø¨ Ø­Ø±Ø§Ø±ØªÛŒ": ["Ø§Ø³Ù¾Ø±ÛŒ", "Ø³Ø´ÙˆØ§Ø±", "Ú†Ø³Ø¨ Ø­Ø±Ø§Ø±ØªÛŒ", "soldering iron", "heat resistant glue"],
    "Ø³ÛŒÙ… Ú†ÛŒÙ†ØŒ Ú©Ù Ú†ÛŒÙ† Ùˆ Ù„Ø®Øª Ú©Ù†": ["Ø³ÛŒÙ… Ú†ÛŒÙ†", "Ú©Ù Ú†ÛŒÙ†", "Ù„Ø®Øª Ú©Ù†", "wire stripper", "wire cutter"],
    "Ø§Ù†Ø¨Ø±Ø¯Ø³Øª Ùˆ Ø¯Ù… Ø¨Ø§Ø±ÛŒÚ©": ["Ø§Ù†Ø¨Ø±Ø¯Ø³Øª", "Ø¯Ù… Ø¨Ø§Ø±ÛŒÚ©", "pliers", "thin nose pliers"],
    "Ù¾Ù†Ø³ØŒ ØªÛŒØºÙ‡ Ùˆ Ú©Ø§ØªØ±": ["Ù¾Ù†Ø³", "ØªÛŒØºÙ‡", "Ú©Ø§ØªØ±", "tweezers", "blade", "cutter"],
    "Ú†Ø³Ø¨ Ù†Ø³ÙˆØ² Ùˆ Ø³Ø§Ø¯Ù‡": ["Ú†Ø³Ø¨ Ù†Ø³ÙˆØ²", "Ú†Ø³Ø¨ Ø³Ø§Ø¯Ù‡", "heat resistant glue", "adhesive"],
    "Ø¬Ø¹Ø¨Ù‡ Ø§Ø¨Ø²Ø§Ø± Ùˆ Ù‚Ø·Ø¹Ø§Øª": ["Ø¬Ø¹Ø¨Ù‡ Ø§Ø¨Ø²Ø§Ø±", "Ù‚Ø·Ø¹Ø§Øª", "tool box", "parts"],
    "Ø§ØªØµØ§Ù„Ø§Øª Ù…Ú©Ø§Ù†ÛŒÚ©ÛŒ": ["Ø§ØªØµØ§Ù„Ø§Øª Ù…Ú©Ø§Ù†ÛŒÚ©ÛŒ", "mechanical connections", "mechanical joints"],
    "Ø´Ø§Ø³ÛŒ Ø±Ø¨Ø§Øª": ["Ø´Ø§Ø³ÛŒ Ø±Ø¨Ø§Øª", "robot chassis", "frame"],
    "Ú†Ø±Ø® Ø±Ø¨Ø§Øª": ["Ú†Ø±Ø® Ø±Ø¨Ø§Øª", "robot wheel", "wheel"],
    "Ù…ÙˆØªÙˆØ±": ["Ù…ÙˆØªÙˆØ±", "motor"],
    "Ù…Ù„Ø® Ù¾Ø±ÙˆØ§Ø²ÛŒ": ["Ù…Ù„Ø® Ù¾Ø±ÙˆØ§Ø²ÛŒ", "propeller", "flying propeller"],
    "Ø¯Ø³ØªÙ‡ Ú©Ù†ØªØ±Ù„": ["Ø¯Ø³ØªÙ‡ Ú©Ù†ØªØ±Ù„", "control handle", "joystick"],
    "Ú†Ø±Ø® Ø¯Ù†Ø¯Ù‡": ["Ú†Ø±Ø® Ø¯Ù†Ø¯Ù‡", "gear", "gear wheel"],
    "ÙÙ„Ø§ÛŒØª Ú©Ù†ØªØ±Ù„ Ø±Ø¨Ø§Øª": ["ÙÙ„Ø§ÛŒØª Ú©Ù†ØªØ±Ù„", "flight controller", "robot flight control"],
    "Ù¾ÛŒØ´ Ø³Ø§Ø®ØªÙ‡": ["Ù¾ÛŒØ´ Ø³Ø§Ø®ØªÙ‡", "premade", "kit"],
    "Ø³ÙˆÙ„ÙˆÙ†ÙˆØ¦ÛŒØ¯": ["Ø³ÙˆÙ„ÙˆÙ†ÙˆØ¦ÛŒØ¯", "solenoid"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ø§ÙˆÙ„ØªØ±Ø§Ø³ÙˆÙ†ÛŒÚ© - ÙØ§ØµÙ„Ù‡ Ø³Ù†Ø¬": ["Ù…Ø§Ú˜ÙˆÙ„ Ø§ÙˆÙ„ØªØ±Ø§Ø³ÙˆÙ†ÛŒÚ©", "ÙØ§ØµÙ„Ù‡ Ø³Ù†Ø¬", "ultrasonic module", "distance sensor"],
    "Ù…Ø§Ú˜ÙˆÙ„ ØªØ§Ú† Ùˆ Ø§Ø«Ø± Ø§Ù†Ú¯Ø´Øª": ["Ù…Ø§Ú˜ÙˆÙ„ ØªØ§Ú†", "Ø§Ø«Ø± Ø§Ù†Ú¯Ø´Øª", "touch module", "fingerprint module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ùˆ Ø³Ù†Ø³ÙˆØ± Ø¨Ø®Ø§Ø± Ø³Ø±Ø¯": ["Ù…Ø§Ú˜ÙˆÙ„ Ø¨Ø®Ø§Ø±", "Ø³Ù†Ø³ÙˆØ± Ø¨Ø®Ø§Ø±", "vapor sensor", "cool vapor sensor"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± Ùˆ Ø¯ÙˆØ±Ø¨ÛŒÙ†": ["Ù…Ø§Ú˜ÙˆÙ„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±", "Ø¯ÙˆØ±Ø¨ÛŒÙ†", "camera module", "image processing module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ù¾Ø±ÛŒÙ†ØªØ±ØŒ Ú†Ø§Ù¾Ú¯Ø±": ["Ù…Ø§Ú˜ÙˆÙ„ Ù¾Ø±ÛŒÙ†ØªØ±", "Ú†Ø§Ù¾Ú¯Ø±", "printer module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ù¾Ø²Ø´Ú©ÛŒ": ["Ù…Ø§Ú˜ÙˆÙ„ Ù¾Ø²Ø´Ú©ÛŒ", "medical module"],
    "Ù…Ø§Ú˜ÙˆÙ„ ØªØºØ°ÛŒÙ‡ - ÙˆÙ„ØªØ§Ú˜ Ùˆ Ø´Ø§Ø±Ú˜": ["Ù…Ø§Ú˜ÙˆÙ„ ØªØºØ°ÛŒÙ‡", "ÙˆÙ„ØªØ§Ú˜", "Ø´Ø§Ø±Ú˜", "power module", "voltage module"],
    "ÙˆÙ„Øª Ù…ØªØ± Ùˆ Ø¢Ù…Ù¾Ø± Ù…ØªØ± Ø±ÙˆÙ¾Ù†Ù„ÛŒ": ["ÙˆÙ„Øª Ù…ØªØ±", "Ø¢Ù…Ù¾Ø± Ù…ØªØ±", "rohde schwarz", "voltmeter", "ammeter"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ø¬Ø±ÛŒØ§Ù†": ["Ù…Ø§Ú˜ÙˆÙ„ Ø¬Ø±ÛŒØ§Ù†", "current module"],
    "Ù…Ø§Ú˜ÙˆÙ„ ØªØ§ÛŒÙ…Ø± Ùˆ Ù¾Ø§Ù„Ø³": ["Ù…Ø§Ú˜ÙˆÙ„ ØªØ§ÛŒÙ…Ø±", "Ù¾Ø§Ù„Ø³", "timer module", "pulse module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ø­Ø±Ú©Øª Ùˆ Ù„Ø±Ø²Ø´": ["Ù…Ø§Ú˜ÙˆÙ„ Ø­Ø±Ú©Øª", "Ù„Ø±Ø²Ø´", "motion module", "vibration module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ø¯Ø±Ø§ÛŒÙˆØ± Ù…ÙˆØªÙˆØ±": ["Ù…Ø§Ú˜ÙˆÙ„ Ø¯Ø±Ø§ÛŒÙˆØ± Ù…ÙˆØªÙˆØ±", "motor driver module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ø¯Ù…Ø§ Ùˆ Ø±Ø·ÙˆØ¨Øª": ["Ù…Ø§Ú˜ÙˆÙ„ Ø¯Ù…Ø§", "Ø±Ø·ÙˆØ¨Øª", "temperature module", "humidity module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ù†Ù…Ø§ÛŒØ´Ú¯Ø±": ["Ù…Ø§Ú˜ÙˆÙ„ Ù†Ù…Ø§ÛŒØ´Ú¯Ø±", "display module"],
    "Ù…Ø§Ú˜ÙˆÙ„ LED Ùˆ Ø³Ú¯Ù…Ù†Øª": ["Ù…Ø§Ú˜ÙˆÙ„ LED", "Ø³Ú¯Ù…Ù†Øª", "led module", "segment module"],
    "Ø±ÛŒÙ…ÙˆØª Ùˆ Ù…Ø§Ú˜ÙˆÙ„ Ù‡Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø·ÛŒ RF": ["Ø±ÛŒÙ…ÙˆØª", "RF", "remote", "rf module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ø´ØªØ§Ø¨ Ø³Ù†Ø¬ Ùˆ Ú˜ÛŒØ±ÙˆØ³Ú©ÙˆÙ¾": ["Ù…Ø§Ú˜ÙˆÙ„ Ø´ØªØ§Ø¨ Ø³Ù†Ø¬", "Ú˜ÛŒØ±ÙˆØ³Ú©ÙˆÙ¾", "accelerometer", "gyroscope"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ø´Ø¨Ú©Ù‡ Ùˆ WIFI": ["Ù…Ø§Ú˜ÙˆÙ„ Ø´Ø¨Ú©Ù‡", "WIFI", "network module", "wifi module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ù‡Ø§ÛŒ ESP Ùˆ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø§Ø´ÛŒØ§": ["ESP", "Ø§ÛŒÙ†ØªØ±Ù†Øª Ø§Ø´ÛŒØ§", "esp module", "iot module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ø¨Ù„ÙˆØªÙˆØ« Bluetooth": ["Ù…Ø§Ú˜ÙˆÙ„ Ø¨Ù„ÙˆØªÙˆØ«", "bluetooth", "bluetooth module"],
    "Ù…Ø§Ú˜ÙˆÙ„ ØµÙˆØªÛŒ": ["Ù…Ø§Ú˜ÙˆÙ„ ØµÙˆØªÛŒ", "audio module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ù‡Ø§ÛŒ ÙˆØ²Ù†ØŒ Ù†ÛŒØ±Ùˆ Ùˆ ÙØ´Ø§Ø±": ["Ù…Ø§Ú˜ÙˆÙ„ ÙˆØ²Ù†", "Ù†ÛŒØ±Ùˆ", "ÙØ´Ø§Ø±", "weight module", "force module", "pressure module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ùˆ Ø³Ù†Ø³ÙˆØ± Ú¯Ø§Ø²": ["Ù…Ø§Ú˜ÙˆÙ„ Ú¯Ø§Ø²", "Ø³Ù†Ø³ÙˆØ± Ú¯Ø§Ø²", "gas module", "gas sensor"],
    "Ø¯ÛŒÙ…Ø±Ù‡Ø§ÛŒ DC Ùˆ AC": ["Ø¯ÛŒÙ…Ø± DC", "Ø¯ÛŒÙ…Ø± AC", "dc dimmer", "ac dimmer"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ù…Ø¨Ø¯Ù„ Ùˆ ÙˆØ§Ø³Ø·": ["Ù…Ø§Ú˜ÙˆÙ„ Ù…Ø¨Ø¯Ù„", "ÙˆØ§Ø³Ø·", "converter module", "interface module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ø±Ù„Ù‡ Ùˆ Ø³ÙˆØ¦ÛŒÚ†": ["Ù…Ø§Ú˜ÙˆÙ„ Ø±Ù„Ù‡", "Ø³ÙˆØ¦ÛŒÚ†", "relay module", "switch module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ùˆ Ø³ÙˆØ¦ÛŒÚ† PIR": ["Ù…Ø§Ú˜ÙˆÙ„ PIR", "PIR", "pir module", "pir sensor"],
    "Ù…Ø§Ú˜ÙˆÙ„ GPS - GSM - GPRS": ["GPS", "GSM", "GPRS", "gps module", "gsm module", "gprs module"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ùˆ ØªÚ¯ RFID": ["Ù…Ø§Ú˜ÙˆÙ„ RFID", "RFID", "rfid module", "rfid tag"],
    "Ú©ÙˆØ±Ù‡ Ø§Ù„Ù‚Ø§ÛŒÛŒ ZVS": ["Ú©ÙˆØ±Ù‡ Ø§Ù„Ù‚Ø§ÛŒÛŒ", "ZVS", "induction heater", "zvs"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ù…Ø§Ø¯ÙˆÙ† Ù‚Ø±Ù…Ø² IR": ["Ù…Ø§Ú˜ÙˆÙ„ IR", "IR", "ir module", "infrared module"],
    "Ø³Ø§ÛŒØ± Ù…Ø§Ú˜ÙˆÙ„ Ù‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ": ["Ø³Ø§ÛŒØ± Ù…Ø§Ú˜ÙˆÙ„", "other module", "miscellaneous module"],
    "Ø¢Ø¯Ø§Ù¾ØªÙˆØ±ØŒ Ø³ÙˆØ¦ÛŒÚ†ÛŒÙ†Ú¯ Ùˆ Ø§ÛŒÙ†ÙˆØ±ØªØ±": ["Ø¢Ø¯Ø§Ù¾ØªÙˆØ±", "Ø³ÙˆØ¦ÛŒÚ†ÛŒÙ†Ú¯", "Ø§ÛŒÙ†ÙˆØ±ØªØ±", "adapter", "switching", "inverter"],
    "Ø¨Ø§ØªØ±ÛŒØŒ Ø¬Ø§Ø¨Ø§ØªØ±ÛŒ Ùˆ Ø´Ø§Ø±Ú˜Ø±": ["Ø¨Ø§ØªØ±ÛŒ", "Ø´Ø§Ø±Ú˜Ø±", "battery", "charger"],
    "Ù…Ø§Ú˜ÙˆÙ„ ØªØºØ°ÛŒÙ‡ Ùˆ Ø´Ø§Ø±Ú˜Ø± Ø²Ø¨Ø±ÛŒ Ù¾Ø§ÛŒ": ["Ù…Ø§Ú˜ÙˆÙ„ ØªØºØ°ÛŒÙ‡ Ø²Ø¨Ø±ÛŒ Ù¾Ø§ÛŒ", "raspberry pi power module"],
    "Ø±Ø²Ø¨Ø±ÛŒ Ù¾Ø§ÛŒ Raspberry Pi": ["Ø±Ø²Ø¨Ø±ÛŒ Ù¾Ø§ÛŒ", "raspberry pi", "raspberry"],
    "Ù…ÛŒÙ†ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ± Ù„ÛŒÙ†ÙˆÚ©Ø³ÛŒ - Ø§Ù†Ø¯Ø±ÙˆÛŒØ¯ÛŒ": ["Ù…ÛŒÙ†ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ± Ù„ÛŒÙ†ÙˆÚ©Ø³ÛŒ", "Ø§Ù†Ø¯Ø±ÙˆÛŒØ¯ÛŒ", "linux mini computer", "android mini computer"],
    "ØªÛŒ ÙˆÛŒ Ø¨Ø§Ú©Ø³ TV BOX": ["ØªÛŒ ÙˆÛŒ Ø¨Ø§Ú©Ø³", "tv box", "tvbox"],
    "Ù…ÛŒÙ†ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ± ÙˆÛŒÙ†Ø¯ÙˆØ²ÛŒ": ["Ù…ÛŒÙ†ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ± ÙˆÛŒÙ†Ø¯ÙˆØ²ÛŒ", "windows mini computer"],
    "Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ Orange Pi": ["Orange Pi", "orange pi", "opi"],
    "Ù†Ù…Ø§ÛŒØ´Ú¯Ø± TFT": ["Ù†Ù…Ø§ÛŒØ´Ú¯Ø± TFT", "tft display"],
    "Ù†Ù…Ø§ÛŒØ´Ú¯Ø± OLED": ["Ù†Ù…Ø§ÛŒØ´Ú¯Ø± OLED", "oled display"],
    "Ù†Ù…Ø§ÛŒØ´Ú¯Ø± LCD/GLCD": ["Ù†Ù…Ø§ÛŒØ´Ú¯Ø± LCD", "GLCD", "lcd display", "glcd display"],
    "Ù…Ø§Ú˜ÙˆÙ„ Ù†Ù…Ø§ÛŒØ´Ú¯Ø±": ["Ù…Ø§Ú˜ÙˆÙ„ Ù†Ù…Ø§ÛŒØ´Ú¯Ø±", "display module"],
    "Ù†Ù…Ø§ÛŒØ´Ú¯Ø± HDMI/VGA": ["Ù†Ù…Ø§ÛŒØ´Ú¯Ø± HDMI", "VGA", "hdmi display", "vga display"],
    "ØªØ¬Ù‡ÛŒØ²Ø§Øª Ø­ÙØ§Ø¸ØªÛŒ Ùˆ Ú©Ù†ØªØ±Ù„ÛŒ": ["ØªØ¬Ù‡ÛŒØ²Ø§Øª Ø­ÙØ§Ø¸ØªÛŒ", "ØªØ¬Ù‡ÛŒØ²Ø§Øª Ú©Ù†ØªØ±Ù„ÛŒ", "safety equipment", "control equipment"],
    "Ù…ØªÙØ±Ù‚Ù‡": []  # Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø¯ÙˆÙ† Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
}

visited_urls = set()
scraped_count = 0
category_counts = {cat: 0 for cat in CATEGORIES.keys()}

def load_scraped_urls(filepath: str) -> set:
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„ÛŒØ³Øª URLÙ‡Ø§ÛŒ Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ø³Ú©Ø±Ù¾ Ø´Ø¯Ù‡"""
    if os.path.exists(filepath):
        with open(filepath, "r", encoding="utf-8") as f:
            return set(line.strip() for line in f if line.strip())
    return set()

def save_scraped_url(filepath: str, url: str):
    """Ø°Ø®ÛŒØ±Ù‡ URL Ø§Ø³Ú©Ø±Ù¾ Ø´Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„"""
    with open(filepath, "a", encoding="utf-8") as f:
        f.write(f"{url}\n")

def detect_category(title: str) -> str:
    """ØªØ´Ø®ÛŒØµ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù†ÙˆØ§Ù†"""
    text = title.lower()
    
    for category, keywords in CATEGORIES.items():
        if category == "Ù…ØªÙØ±Ù‚Ù‡":
            continue
        for keyword in keywords:
            if keyword.lower() in text:
                return category
    
    return "Ù…ØªÙØ±Ù‚Ù‡"

async def extract_product_info(page, url: str):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø­ØµÙˆÙ„ Ø§Ø² ÛŒÚ© ØµÙØ­Ù‡"""
    result = f"URL: {url}\n{'='*80}\n\n"
    
    title = ""
    # 1. Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ Ù…Ø­ØµÙˆÙ„
    try:
        title_element = await page.query_selector("h1")
        if title_element:
            title = await title_element.inner_text()
            result += f"=== Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ ===\n{title.strip()}\n\n"
    except:
        result += "=== Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ ===\nÛŒØ§ÙØª Ù†Ø´Ø¯\n\n"
    
    # 2. Ø¹Ù†ÙˆØ§Ù† Ø¯ÙˆÙ…/Ø²ÛŒØ±Ø¹Ù†ÙˆØ§Ù†
    try:
        subtitle_element = await page.query_selector("[class*='desc']")
        if subtitle_element:
            subtitle = await subtitle_element.inner_text()
            result += f"=== Ø¹Ù†ÙˆØ§Ù† Ø¯ÙˆÙ… ===\n{subtitle.strip()}\n\n"
    except:
        result += "=== Ø¹Ù†ÙˆØ§Ù† Ø¯ÙˆÙ… ===\nÛŒØ§ÙØª Ù†Ø´Ø¯\n\n"
    
    # 3. ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„
    try:
        description_element = await page.query_selector(".product-description")
        if description_element:
            description = await description_element.inner_text()
            result += f"=== ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„ ===\n{description.strip()}\n\n"
    except:
        result += "=== ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„ ===\nÛŒØ§ÙØª Ù†Ø´Ø¯\n\n"
    
    # 4. Ù‚ÛŒÙ…Øª
    try:
        price_element = await page.query_selector("span.current-price.fa-number-conv")
        if price_element:
            price = await price_element.inner_text()
            result += f"=== Ù‚ÛŒÙ…Øª ===\n{price.strip()}\n\n"
    except:
        result += "=== Ù‚ÛŒÙ…Øª ===\nÛŒØ§ÙØª Ù†Ø´Ø¯\n\n"
    
    return result, title

async def get_all_links(page, base_url: str):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ…Ø§Ù… Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø§Ø² ØµÙØ­Ù‡"""
    links = set()
    try:
        all_links = await page.query_selector_all("a[href]")
        for link in all_links:
            href = await link.get_attribute("href")
            if href:
                full_url = urljoin(base_url, href)
                parsed = urlparse(full_url)
                if parsed.netloc == urlparse(base_url).netloc:
                    links.add(full_url)
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§: {e}")
    
    return links

async def scrape_page(page, url: str, output_dir: str, scraped_urls_file: str):
    """Ø§Ø³Ú©Ø±ÙÛŒÙ¾ ÛŒÚ© ØµÙØ­Ù‡ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª"""
    global scraped_count, category_counts
    
    try:
        print(f"Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³Ú©Ø±ÙÛŒÙ¾: {url}")
        await page.goto(url, wait_until="networkidle", timeout=30000)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
        content, title = await extract_product_info(page, url)
        
        # ØªØ´Ø®ÛŒØµ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
        category = detect_category(title)
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
        category_dir = os.path.join(output_dir, category)
        os.makedirs(category_dir, exist_ok=True)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„
        filename = f"page_{category_counts[category]:04d}.txt"
        filepath = os.path.join(category_dir, filename)
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        
        # Ø°Ø®ÛŒØ±Ù‡ URL Ø¯Ø± ÙØ§ÛŒÙ„ URLÙ‡Ø§ÛŒ Ø§Ø³Ú©Ø±Ù¾ Ø´Ø¯Ù‡
        save_scraped_url(scraped_urls_file, url)
        
        category_counts[category] += 1
        scraped_count += 1
        print(f"âœ“ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø± [{category}]: {filename} (ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„: {scraped_count})")
        
        return True
    except Exception as e:
        print(f"âœ— Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³Ú©Ø±ÙÛŒÙ¾ {url}: {e}")
        return False

async def scrape_domain(base_url: str, output_dir: str, min_delay: int, max_delay: int, max_pages: int = None):
    """Ø§Ø³Ú©Ø±ÙÛŒÙ¾ Ú©Ù„ Ø¯Ø§Ù…Ù†Ù‡ Ø¨Ø§ ÙˆÙ‚ÙÙ‡ ØªØµØ§Ø¯ÙÛŒ"""
    global visited_urls, scraped_count
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø± Ú©Ù†Ø§Ø± ÙØ§ÛŒÙ„ Ú©Ø¯
    script_dir = os.path.dirname(os.path.abspath(__file__))
    full_output_dir = os.path.join(script_dir, output_dir)
    os.makedirs(full_output_dir, exist_ok=True)
    
    # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ URLÙ‡Ø§ÛŒ Ø§Ø³Ú©Ø±Ù¾ Ø´Ø¯Ù‡
    scraped_urls_file = os.path.join(script_dir, SCRAPED_URLS_FILE)
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ URLÙ‡Ø§ÛŒ Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ø³Ú©Ø±Ù¾ Ø´Ø¯Ù‡
    already_scraped = load_scraped_urls(scraped_urls_file)
    visited_urls.update(already_scraped)
    
    if already_scraped:
        print(f"ğŸ”„ ØªØ¹Ø¯Ø§Ø¯ {len(already_scraped)} URL Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ø³Ú©Ø±Ù¾ Ø´Ø¯Ù‡ Ø§Ø³Øª Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.\n")
    
    async with async_playwright() as pw:
        browser = await pw.chromium.launch(headless=True)
        page = await browser.new_page()
        
        # ØµÙ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
        to_visit = {base_url}
        
        while to_visit and (max_pages is None or scraped_count < max_pages):
            # Ø§Ù†ØªØ®Ø§Ø¨ Ù„ÛŒÙ†Ú© Ø¨Ø¹Ø¯ÛŒ
            current_url = to_visit.pop()
            
            if current_url in visited_urls:
                continue
            
            visited_urls.add(current_url)
            
            # Ø§Ø³Ú©Ø±ÙÛŒÙ¾ ØµÙØ­Ù‡
            success = await scrape_page(page, current_url, full_output_dir, scraped_urls_file)
            
            if success:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
                new_links = await get_all_links(page, base_url)
                to_visit.update(new_links - visited_urls)
                
                # ÙˆÙ‚ÙÙ‡ ØªØµØ§Ø¯ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø±ÙØªØ§Ø± Ø§Ù†Ø³Ø§Ù†ÛŒ
                delay = random.uniform(min_delay, max_delay)
                print(f"â³ ÙˆÙ‚ÙÙ‡ {delay:.2f} Ø«Ø§Ù†ÛŒÙ‡...\n")
                await asyncio.sleep(delay)
        
        await browser.close()
        
        print(f"\n{'='*80}")
        print(f"Ø§Ø³Ú©Ø±ÙÛŒÙ¾ Ú©Ø§Ù…Ù„ Ø´Ø¯!")
        print(f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ ØµÙØ­Ø§Øª Ø§Ø³Ú©Ø±ÙÛŒÙ¾ Ø´Ø¯Ù‡: {scraped_count}")
        print(f"\nØªÙˆØ²ÛŒØ¹ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§:")
        for category, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):
            if count > 0:
                print(f"  {category}: {count} Ù…Ø­ØµÙˆÙ„")
        print(f"\nÙ…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡: {full_output_dir}")
        print(f"ÙØ§ÛŒÙ„ URLÙ‡Ø§ÛŒ Ø§Ø³Ú©Ø±Ù¾ Ø´Ø¯Ù‡: {scraped_urls_file}")
        print(f"{'='*80}")

if __name__ == "__main__":
    asyncio.run(scrape_domain(BASE_URL, OUTPUT_DIR, MIN_DELAY, MAX_DELAY, MAX_PAGES))
